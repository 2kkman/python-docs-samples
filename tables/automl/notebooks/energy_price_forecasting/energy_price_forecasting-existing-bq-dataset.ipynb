{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"energy_price_forecasting-existing-bq-dataset.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ulXoTerctuhd","colab_type":"code","colab":{}},"source":["# Copyright 2019 Google LLC\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WY_oCqqGt4oV","colab_type":"text"},"source":["# **Energy Forecasting with AutoML Tables**\n","\n","<table align=\"left\">\n","  <td>\n","    <a href=\"https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-keras\">\n","      <img src=\"https://cloud.google.com/_static/images/cloud/icons/favicons/onecloud/super_cloud.png\"\n","           alt=\"Google Cloud logo\" width=\"32px\"> Read on cloud.google.com\n","    </a>\n","  </td>\n","  <td>\n","    <a href=\"#\">\n","      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n","    </a>\n","  </td>\n","  <td>\n","    <a href=\"#\">\n","      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n","      View on GitHub\n","    </a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"OTuvGKRnt_a8","colab_type":"text"},"source":["## **Overview**\n"]},{"cell_type":"markdown","metadata":{"id":"WIwfcofRCtEw","colab_type":"text"},"source":["This guide provides a high-level overview of an energy price forecasting solution, considering the significance of the solution as well as which audiences and use cases it applies to. In this section, we outline the business case for this solution, the problem, the solution, and results. In section 2, we provide the code setup instructions.\n","\n","**Solution description:** Model to forecast hourly energy prices for the next 7 days.\n","\n","**Significance:** This is a good complement to standard demand forecasting models that typically predict N periods in the future. This model does a rolling forecast that is vital for operational decisions. It also takes into consideration historical trends, seasonal patterns, and external factors (like weather) to make more accurate forecasts."]},{"cell_type":"markdown","metadata":{"id":"msllwx52h6s0","colab_type":"text"},"source":["### **Dataset**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4FdutwreiPhc","colab_type":"text"},"source":["**Data Source**\n","\n","  Raw data from the below links are used for the model.\n","* [MarketPricePT](http://complatt.smartwatt.net/assets/files/historicalRealData/RealMarketPriceDataPT.csv) - Historical hourly energy prices.\n","\n","* [historical_weather](http://complatt.smartwatt.net/assets/files/weatherHistoricalData/WeatherHistoricalData.zip) - Historical hourly weather forecasts.\n","\n","*Disclaimer: The data for both tables comes from http://complatt.smartwatt.net/. This website hosts a closed competition meant to solve the energy price forecasting problem. The data was not collected or vetted by Google LLC and hence, we cannot guarantee the veracity or quality of it.\n","\n","The above data is processed and saved as BigQuery Table in `bq://energy-forecasting.Energy.automldata` for easier access"]},{"cell_type":"markdown","metadata":{"id":"0_zjzwofsO_S","colab_type":"text"},"source":["**Data Schema**\n","<table align=\"left\">\n","  <thead>\n","    <tr>\n","      <th> Field name </th>\n","      <th> Datatype </th>\n","      <th> Description </th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>price</td>\n","      <td>FLOAT</td>\n","      <td>Energy price.</td>\n","    </tr> \n","    <tr>\n","      <td>date_utc</td>\n","      <td>TIMESTAMP</td>\n","      <td>Date and hour for specified price.</td>\n","    </tr> \n","    <tr>\n","      <td>day</td>\n","      <td>INTEGER</td>\n","      <td>Day of week.</td>\n","    </tr> \n","    <tr>\n","      <td>hour</td>\n","      <td>INTEGER</td>\n","      <td>Hour of day.</td>\n","    </tr> \n","    <tr>\n","      <td>distribution0 to distribution4</td>\n","      <td>FLOAT</td>\n","      <td>Distribution of hourly prices during the previous week (min, 25th, 50th, 75th, max).</td>\n","    </tr> \n","    <tr>\n","      <td>weather0 to weather179</td>\n","      <td>FLOAT</td>\n","      <td>Weather features. Contains 10 distinct weather metrics (temperature, wind_speed_100m, wind_direction_100m, <br/>air_density, precipitation, wind_gust, radiation, wind_speed, wind_direction, pressure) from 18 distinct parts of the country (180 total features).</td>\n","    </tr> \n","  </tbody>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"SLq3FfRa8E8X","colab_type":"text"},"source":["### **Costs**\n"]},{"cell_type":"markdown","metadata":{"id":"DzxIfOrB71wl","colab_type":"text"},"source":["This tutorial uses billable components of Google Cloud Platform (GCP):\n","\n","* Cloud AI Platform\n","* Cloud Storage\n","* BigQuery\n","* AutoML Tables\n","\n","Learn about [Cloud AI Platform pricing](https://cloud.google.com/ml-engine/docs/pricing), [Cloud Storage pricing](https://cloud.google.com/storage/pricing),[Bigquery pricing](https://cloud.google.com/bigquery/pricing), [AutoML Tables pricing](https://cloud.google.com/automl-tables/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."]},{"cell_type":"markdown","metadata":{"id":"ze4-nDLfK4pw","colab_type":"text"},"source":["## **Set up your local development environment**\n","\n","**If you are using Colab or AI Platform Notebooks**, your environment already meets\n","all the requirements to run this notebook. If you are using **AI Platform Notebook**, make sure the machine configuration type is **1 vCPU, 3.75 GB RAM** or above. You can skip this step."]},{"cell_type":"markdown","metadata":{"id":"gCuSR8GkAgzl","colab_type":"text"},"source":["**Otherwise**, make sure your environment meets this notebook's requirements.\n","You need the following:\n","\n","* The Google Cloud SDK\n","* Git\n","* Python 3\n","* virtualenv\n","* Jupyter notebook running in a virtual environment with Python 3\n","\n","The Google Cloud guide to [Setting up a Python development\n","environment](https://cloud.google.com/python/setup) and the [Jupyter\n","installation guide](https://jupyter.org/install) provide detailed instructions\n","for meeting these requirements. The following steps provide a condensed set of\n","instructions:\n","\n","1. [Install and initialize the Cloud SDK.](https://cloud.google.com/sdk/docs/)\n","\n","2. [Install Python 3.](https://cloud.google.com/python/setup#installing_python)\n","\n","3. [Install\n","   virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)\n","   and create a virtual environment that uses Python 3.\n","\n","4. Activate that environment and run `pip install jupyter` in a shell to install\n","   Jupyter.\n","\n","5. Run `jupyter notebook` in a shell to launch Jupyter.\n","\n","6. Open this notebook in the Jupyter Notebook Dashboard."]},{"cell_type":"markdown","metadata":{"id":"dgpdHTag9aUC","colab_type":"text"},"source":["## **Set up your GCP project**\n","\n","**The following steps are required, regardless of your notebook environment.**\n","\n","1. [Select or create a GCP project.](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n","\n","2. [Make sure that billing is enabled for your project.](https://cloud.google.com/billing/docs/how-to/modify-project)\n","\n","3. [Enable the AI Platform APIs and Compute Engine APIs.](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component)\n","\n","4. [Enable AutoML API.](https://console.cloud.google.com/apis/library/automl.googleapis.com?q=automl)\n"]},{"cell_type":"markdown","metadata":{"id":"Plf6qTgXyYSx","colab_type":"text"},"source":["## **PIP Install Packages and dependencies**\n","\n","Install addional dependencies not installed in the notebook environment."]},{"cell_type":"code","metadata":{"id":"gt5peqa-h9MO","colab_type":"code","colab":{}},"source":["# Use the latest major GA version of the framework.\n","! pip install --quiet google-cloud-automl \n","! pip install --quiet google-cloud-bigquery"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kK5JATKPNf3I","colab_type":"text"},"source":["**Note:** Try installing using `sudo`, if the above command throw any permission errors."]},{"cell_type":"markdown","metadata":{"id":"YeQtfJyL-fKp","colab_type":"text"},"source":["`Restart` the kernel to allow `automl_v1beta1` to be imported for Jupyter Notebooks."]},{"cell_type":"code","metadata":{"id":"Ip6IboKF-rQd","colab_type":"code","colab":{}},"source":["from IPython.core.display import HTML\n","HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9BJNoa2H1opR","colab_type":"text"},"source":["## **Set up your GCP Project Id**\n","\n","Enter your `Project Id` in the cell below. Then run the  cell to make sure the\n","Cloud SDK uses the right project for all the commands in this notebook."]},{"cell_type":"code","metadata":{"id":"7rG4S9q1Pjfg","colab_type":"code","colab":{}},"source":["PROJECT_ID = \"[your-project-id]\" #@param {type:\"string\"}\n","COMPUTE_REGION = \"us-central1\" # Currently only supported region."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dr--iN2kAylZ","colab_type":"text"},"source":["## **Authenticate your GCP account**\n","\n","**If you are using AI Platform Notebooks**, your environment is already\n","authenticated. Skip this step."]},{"cell_type":"markdown","metadata":{"id":"3yyVCJHFSEKG","colab_type":"text"},"source":["Otherwise, follow these steps:\n","\n","1. In the GCP Console, go to the [**Create service account key**\n","   page](https://console.cloud.google.com/apis/credentials/serviceaccountkey).\n","\n","2. From the **Service account** drop-down list, select **New service account**.\n","\n","3. In the **Service account name** field, enter a name.\n","\n","4. From the **Role** drop-down list, select\n","   **AutoML > AutoML Admin**, \n","   **Storage > Storage Object Admin**, \n","   **BigQuery > BigQuery Admin**.\n","\n","5. Click *Create*. A JSON file that contains your key downloads to your\n","local environment."]},{"cell_type":"markdown","metadata":{"id":"Yt6PhVG0UdF1","colab_type":"text"},"source":["**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."]},{"cell_type":"code","metadata":{"id":"q5TeVHKDMOJF","colab_type":"code","colab":{}},"source":["import sys\n","\n","# Upload the downloaded JSON file that contains your key.\n","if 'google.colab' in sys.modules:    \n","  from google.colab import files\n","  keyfile_upload = files.upload()\n","  keyfile = list(keyfile_upload.keys())[0]\n","  %env GOOGLE_APPLICATION_CREDENTIALS $keyfile\n","  ! gcloud auth activate-service-account --key-file $keyfile"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d1bnPeDVMR5Q","colab_type":"text"},"source":["***If you are running the notebook locally***, enter the path to your service account key as the `GOOGLE_APPLICATION_CREDENTIALS` variable in the cell below and run the cell"]},{"cell_type":"code","metadata":{"id":"fsVNKXESYoeQ","colab_type":"code","colab":{}},"source":["# If you are running this notebook locally, replace the string below with the\n","# path to your service account key and run this cell to authenticate your GCP\n","# account.\n","\n","%env GOOGLE_APPLICATION_CREDENTIALS /path/to/service/account\n","! gcloud auth activate-service-account --key-file '/path/to/service/account'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ztLNd4NM1i7C","colab_type":"text"},"source":["## **Import libraries and define constants**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-dB1h7L2eKuj"},"source":["Import relevant packages.\n"]},{"cell_type":"code","metadata":{"id":"vRK0FR332vhR","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"adugky1YSYmz","colab_type":"code","colab":{}},"source":["from google.cloud import automl_v1beta1 as automl\n","from google.cloud import bigquery\n","import google.cloud.automl_v1beta1.proto.data_types_pb2 as data_types"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BbfLaWRs2TR7","colab_type":"text"},"source":["Populate the following cell with the necessary constants and run it to initialize constants."]},{"cell_type":"code","metadata":{"id":"cVfhqUK_h0CO","colab_type":"code","colab":{}},"source":["#@title Constants { vertical-output: true }\n","\n","# A name for the AutoML tables Dataset to create.\n","DATASET_DISPLAY_NAME = 'energy_forcasting_solution' #@param {type:'string'}\n","# The BigQuery project id to import data from.\n","BQ_PROJECT_ID = \"energy-forecasting\"\n","# The BigQuery dataset to import data from.\n","BQ_DATASET_NAME = \"Energy\" \n","# The BigQuery table to import data from.\n","BQ_TABLE_NAME = \"automldata\"\n","# A name for the AutoML tables model to create.\n","MODEL_DISPLAY_NAME = 'energy_model' #@param {type:'string'}\n","\n","assert all([\n","    PROJECT_ID,\n","    COMPUTE_REGION,\n","    DATASET_DISPLAY_NAME,\n","    BQ_DATASET_NAME,\n","    BQ_TABLE_NAME,\n","    MODEL_DISPLAY_NAME,\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NI_N8n1PC_5l","colab_type":"text"},"source":["Initialize the clients for AutoML, AutoML Tables and BigQuery."]},{"cell_type":"code","metadata":{"id":"gzG8ieSbSfa3","colab_type":"code","colab":{}},"source":["# Initialize the clients.\n","automl_client = automl.AutoMlClient()\n","tables_client = automl.TablesClient(project=PROJECT_ID, region=COMPUTE_REGION)\n","bq_client = bigquery.Client()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xdJykMXDozoP","colab_type":"text"},"source":["## **Test the set up**\n","\n","To test whether your project set up and authentication steps were successful, run the following cell to list your datasets in this project.\n","\n","If no dataset has previously imported into AutoML Tables, you shall expect an empty return."]},{"cell_type":"code","metadata":{"id":"_dKylOQTpF58","colab_type":"code","colab":{}},"source":["# List the datasets.\n","list_datasets = tables_client.list_datasets()\n","datasets = { dataset.display_name: dataset.name for dataset in list_datasets }\n","datasets"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dleTdOMaplSM","colab_type":"text"},"source":["You can also print the list of your models by running the following cell.\n","\n","If no model has previously trained using AutoML Tables, you shall expect an empty return.\n"]},{"cell_type":"code","metadata":{"id":"tMXP6no1pn9p","colab_type":"code","colab":{}},"source":["# List the models.\n","list_models = tables_client.list_models()\n","models = { model.display_name: model.name for model in list_models }\n","models"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rgyQnf6_biGC","colab_type":"text"},"source":["## **Import training data**"]},{"cell_type":"markdown","metadata":{"id":"c33KPWnZbtWB","colab_type":"text"},"source":["### **Create dataset**\n","Select a dataset display name and pass your table source information to create a new dataset."]},{"cell_type":"code","metadata":{"id":"pRvDu-SkS_3e","colab_type":"code","colab":{}},"source":["# Create dataset.\n","dataset = tables_client.create_dataset(\n","    dataset_display_name=DATASET_DISPLAY_NAME)\n","dataset_name = dataset.name\n","dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pcRjwXTicZXo","colab_type":"text"},"source":["### **Import data**\n"]},{"cell_type":"markdown","metadata":{"id":"GmsuW6mSEKV7","colab_type":"text"},"source":["You can import your data to AutoML Tables from GCS or BigQuery. You can create a GCS bucket and upload the data into your bucket. The URI for your file is `gs://BUCKET_NAME/FOLDER_NAME1/FOLDER_NAME2/.../FILE_NAME`. Alternatively you can create a BigQuery table and upload the data into the table. The URI for your table is `bq://PROJECT_ID.DATASET_ID.TABLE_ID`.\n","\n","Importing data may take a few minutes or hours depending on the size of your data. **If your Colab times out**, run the following command to retrieve your dataset. Replace `dataset_name` with its actual value obtained in the preceding cells.\n","\n","    # This will work if your display name ('energy_forecasting_solution') is unique to your project.\n","      dataset = tables_client.get_dataset(dataset_display_name=DATASET_DISPLAY_NAME)\n","    # OR, if you have multiple datasets with the same display name ('energy_forecasting_solution'), use the\n","    # unique indentifier acquired from the above cell ( print(dataset.name) ).\n","      dataset = tables_client.get_dataset(dataset_name=dataset_name)"]},{"cell_type":"code","metadata":{"id":"DViqoYzkWCzX","colab_type":"code","colab":{}},"source":["# Import data from BigQuery.\n","dataset_bq_input_uri = \"bq://{}.{}.{}\".format(\n","    BQ_PROJECT_ID, BQ_DATASET_NAME, BQ_TABLE_NAME)\n","\n","import_data_response = tables_client.import_data(\n","    dataset=dataset,\n","    bigquery_input_uri=dataset_bq_input_uri\n",")\n","\n","print('Dataset import operation: {}'.format(import_data_response.operation))\n","\n","# Wait until import is done.\n","print('Dataset import result: {}'.format(import_data_response.result()))\n","\n","# Verify the status by checking the example_count field.\n","dataset = tables_client.get_dataset(dataset_name=dataset_name)\n","dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mn79lnuydcDI","colab_type":"text"},"source":["## **Review the specs**\n","Run the following command to see table specs such as row count."]},{"cell_type":"code","metadata":{"id":"S7hMflwuWrZS","colab_type":"code","colab":{}},"source":["# List table specs.\n","list_table_specs_response = tables_client.list_table_specs(dataset=dataset)\n","table_specs = [s for s in list_table_specs_response]\n","\n","# List column specs.\n","list_column_specs_response = tables_client.list_column_specs(dataset=dataset)\n","column_specs = {s.display_name: s for s in list_column_specs_response}\n","\n","# Print Features and data_type.\n","features = [(key, data_types.TypeCode.Name(value.data_type.type_code)) \n","            for key, value in column_specs.items()]\n","print('Feature list:\\n')\n","for feature in features:\n","    print(feature[0],':', feature[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FSiCtNjLdnCP","colab_type":"text"},"source":["## **Update dataset: assign a label column and enable nullable columns**\n"]},{"cell_type":"markdown","metadata":{"id":"OqaoRU4MD7-u","colab_type":"text"},"source":["AutoML Tables automatically detects your data column type. For example, for the [Iris dataset](https://storage.cloud.google.com/rostam-193618-tutorial/automl-tables-v1beta1/iris.csv) it detects `species` to be categorical and `petal_length`, `petal_width`, `sepal_length`, and `sepal_width` to be numerical. Depending on the type of your label column, AutoML Tables chooses to run a classification or regression model. If your label column contains only numerical values, but they represent categories, change your label column type to categorical by updating your schema."]},{"cell_type":"markdown","metadata":{"id":"IW_r5eKJfKbL","colab_type":"text"},"source":["### **Update a column: set as categorical**"]},{"cell_type":"code","metadata":{"id":"S2ve2tPGW695","colab_type":"code","colab":{}},"source":["# Update column.\n","column_to_category = 'hour' #@param {type: 'string'}\n","type_code = 'CATEGORY' #@param {type: 'string'}\n","update_column_response = tables_client.update_column_spec(\n","    dataset=dataset,\n","    column_spec_display_name=column_to_category,\n","    type_code=type_code\n",")\n","\n","update_column_response.display_name, update_column_response.data_type"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jtKAKRBbfXvc","colab_type":"text"},"source":["### **Update dataset: assign a target and split column**"]},{"cell_type":"code","metadata":{"id":"SPEIMDfGW-7K","colab_type":"code","colab":{}},"source":["# Set target and split column.\n","target_column_name = 'price' #@param {type: 'string'}\n","split_column_name = 'split' #@param {type: 'string'}\n","\n","tables_client.set_target_column(\n","    dataset=dataset,\n","    column_spec_display_name=target_column_name,\n",")\n","\n","tables_client.set_test_train_column(\n","    dataset=dataset,\n","    column_spec_display_name=split_column_name,\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9xXJquSrfp-2","colab_type":"text"},"source":["## **Creating a model**"]},{"cell_type":"markdown","metadata":{"id":"hsPvMxDKfzIr","colab_type":"text"},"source":["### **Train a model**\n","Specify the duration of the training. For example, `'train_budget_milli_node_hours': 1000` runs the training for one hour. You can increase that number up to a maximum of 72 hours `('train_budget_milli_node_hours': 72000)` for the best model performance.\n","\n","Even with a budget of 1 node hour (the minimum possible budget), training a model can take more than the specified node hours\n","\n","If your Colab times out, use `tables_client.list_models()` to check whether your model has been created. Then use model name to continue to the next steps. Run the following command to retrieve your model.\n","\n","    model = tables_client.get_model(model_display_name=MODEL_DISPLAY_NAME)\n","\n","You can also select the objective to optimize your model training by setting optimization_objective. This solution optimizes the model by minimizing mean absolute error (MAE)."]},{"cell_type":"code","metadata":{"id":"3ZIGJK1PXCKO","colab_type":"code","colab":{}},"source":["# The number of hours to train the model.\n","model_train_hours = 1 #@param {type:'integer'}\n","# Set optimization objective to train the model.\n","model_optimization_objective = 'MINIMIZE_MAE' #@param {type:'string'}\n","\n","create_model_response = tables_client.create_model(\n","    model_display_name=MODEL_DISPLAY_NAME,\n","    dataset=dataset,\n","    optimization_objective=model_optimization_objective,\n","    train_budget_milli_node_hours=model_train_hours*1000,\n",")\n","\n","operation_id = create_model_response.operation.name\n","\n","print('Create model operation: {}'.format(create_model_response.operation))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8kpxm6ZVFyPX","colab_type":"code","colab":{}},"source":["# Wait until model training is done.\n","model = create_model_response.result()\n","model_name = model.name\n","model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fHlJz0bJgTqN","colab_type":"text"},"source":["## **Evaluation Metrics**"]},{"cell_type":"code","metadata":{"id":"z5r_zAOlXHVP","colab_type":"code","colab":{}},"source":["# List evaluation metrics.\n","metrics = [x for x in tables_client.list_model_evaluations(model=model)][-1]\n","metrics.regression_evaluation_metrics"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15SwjxfNgaBg","colab_type":"text"},"source":["## **Get Model**"]},{"cell_type":"code","metadata":{"id":"XoEYjw4kXRnl","colab_type":"code","colab":{}},"source":["# Get model info.\n","model = tables_client.get_model(model_name=model_name)\n","model.name"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OYdugerMgioA","colab_type":"text"},"source":["## **Feature Importance**"]},{"cell_type":"code","metadata":{"id":"eiyGlQVFXdrp","colab_type":"code","colab":{}},"source":["# List column features.\n","feat_list = [(x.feature_importance, x.column_display_name) \n","            for x in model.tables_model_metadata.\\\n","            tables_model_column_info]\n","feat_list.sort(reverse=True)\n","# Only the top features are listed.\n","feat_list[:15]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1w6CT9kREu_Z","colab_type":"text"},"source":["## **Cleaning up**\n","\n","To clean up all GCP resources used in this project, you can [delete the GCP\n","project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n","\n","**Delete BigQuery datasets**\n","\n","In order to delete BigQuery tables, make sure the service account linked to this notebook has a role with the bigquery.tables.delete permission such as Big Query Data Owner. The following command displays the current service account.\n","\n","IAM permissions can be adjusted [here](https://console.cloud.google.com/navigation-error;errorUrl=%2Fiam-admin%2Fiam%3Fproject%3Dprj-automl-notebook&folder%3D&organizationId%3D/permissions)."]},{"cell_type":"code","metadata":{"id":"Pry8_3bxh0DM","colab_type":"code","colab":{}},"source":["# Delete model resource.\n","tables_client.delete_model(model_name=model_name)\n","\n","# Delete dataset resource.\n","tables_client.delete_dataset(dataset_name=dataset_name)\n","\n","# If training model is still running, cancel it.\n","automl_client.transport._operations_client.cancel_operation(operation_id)"],"execution_count":0,"outputs":[]}]}